{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2e5a67-57d4-401d-95be-ee6470e67273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SILVER LAYER - LIMPEZA E VALIDAÇÃO\n",
    "# ============================================\n",
    "# Objetivo: Limpar, validar e enriquecer dados\n",
    "# ============================================\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "SOURCE_TABLE = \"finance_bronze.transacoes_bronze\"\n",
    "TARGET_TABLE = \"finance_silver.transacoes_silver\"\n",
    "\n",
    "print(\" SILVER LAYER - Processamento de Dados\")\n",
    "print(f\" Origem: {SOURCE_TABLE}\")\n",
    "print(f\" Destino: {TARGET_TABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bda585a3-6790-493b-aed1-c4e72d1dcc73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. CARREGAR DADOS BRONZE\n",
    "# ============================================\n",
    "\n",
    "df_bronze = spark.read.table(SOURCE_TABLE)\n",
    "\n",
    "print(f\" Linhas carregadas do Bronze: {df_bronze.count()}\")\n",
    "\n",
    "print(\"\\n Verificando qualidade dos dados antes da limpeza:\")\n",
    "\n",
    "print(\"\\n NULLs por coluna:\")\n",
    "for col in [\"data\", \"descricao\", \"valor\", \"tipo\", \"categoria\"]:\n",
    "    null_count = df_bronze.filter(F.col(col).isNull()).count()\n",
    "    print(f\"   {col}: {null_count} NULLs\")\n",
    "\n",
    "duplicates = df_bronze.groupBy(\"data\", \"descricao\", \"valor\").count() \\\n",
    "    .filter(F.col(\"count\") > 1) \\\n",
    "    .count()\n",
    "print(f\"\\n Registros duplicados: {duplicates}\")\n",
    "\n",
    "invalid_values = df_bronze.filter(F.col(\"valor\") <= 0).count()\n",
    "print(f\"  Valores <= 0: {invalid_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a716cd68-01a6-47d9-a616-0c98a4721327",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. LIMPEZA DE DADOS\n",
    "# ============================================\n",
    "\n",
    "print(\"Inicio limpeza dados: \\n\")\n",
    "\n",
    "linhas_antes = df_bronze.count()\n",
    "print(f\"Linhas ANTES da limpeza: {linhas_antes}\")\n",
    "\n",
    "print(\"\\n 1️. Removendo null em campos críticos\")\n",
    "df_clean = df_bronze.filter(\n",
    "    F.col(\"data\").isNotNull() &\n",
    "    F.col(\"valor\").isNotNull() &\n",
    "    F.col(\"tipo\").isNotNull() &\n",
    "    F.col(\"categoria\").isNotNull()\n",
    ")\n",
    "removidos_null = linhas_antes - df_clean.count()\n",
    "print(f\" Removidos {removidos_null} registros com NULL\")\n",
    "\n",
    "print(\"\\n 2️. Removendo valores invalidos (<=0)...\")\n",
    "linhas_antes_valor = df_clean.count()\n",
    "df_clean = df_clean.filter(F.col(\"valor\") > 0)\n",
    "removidos_valor = linhas_antes_valor - df_clean.count()\n",
    "print(f\"Removidos {removidos_valor} registros com valor <=0\")\n",
    "\n",
    "print(\"\\n 3. Removendo duplicatas...\")\n",
    "linhas_antes_dup = df_clean.count()\n",
    "df_clean = df_clean.dropDuplicates([\"data\", \"descricao\", \"valor\", \"tipo\"])\n",
    "removidos_dup = linhas_antes_dup - df_clean.count()\n",
    "print(f\"Removidos {removidos_dup} registros duplicados\")\n",
    "\n",
    "linhas_depois = df_clean.count()\n",
    "print(f\"\\n Linhas DEPOIS da limpeza: {linhas_depois}\")\n",
    "print(f\" Taxa de retenção: {(linhas_depois/linhas_antes)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fefe7ab8-f83e-4efd-95fa-aae47c1c1d11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. PADRONIZAÇÃO DE DADOS\n",
    "# ============================================\n",
    "\n",
    "print(\"Padronizando formato\\n\")\n",
    "\n",
    "print(\"1️. Convertendo coluna 'data' para tipo DATE...\")\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"data\",\n",
    "    F.to_date(F.col(\"data\"))\n",
    ")\n",
    "\n",
    "print(\"2️. Padronizando descrições...\")\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"descricao\",\n",
    "    F.upper(F.trim(F.col(\"descricao\")))\n",
    ")\n",
    "\n",
    "print(\"3️. Padronizando tipo e categoria...\")\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"tipo\",\n",
    "    F.lower(F.trim(F.col(\"tipo\")))\n",
    ").withColumn(\n",
    "    \"categoria\",\n",
    "    F.trim(F.col(\"categoria\"))\n",
    ")\n",
    "\n",
    "print(\"4️. Arredondando valores para 2 casas decimais...\")\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"valor\",\n",
    "    F.round(F.col(\"valor\"), 2)\n",
    ")\n",
    "\n",
    "print(\"\\n Padronização concluída\")\n",
    "\n",
    "print(\"\\n Amostra de dados padronizados:\")\n",
    "display(df_clean.select(\n",
    "    \"data\", \"descricao\", \"valor\", \"tipo\", \"categoria\"\n",
    ").limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6027b44-8d55-4dca-ac22-752d2a9d5c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PASSO 4: ENRIQUECIMENTO DE DADOS\n",
    "# ============================================\n",
    "# adiciona campos calculados uteis\n",
    "\n",
    "print(\"Adicionando campos calculados...\\n\")\n",
    "\n",
    "print(\"1️. Extraindo ano e mês...\")\n",
    "df_enriched = df_clean.withColumn(\n",
    "    \"ano\",\n",
    "    F.year(F.col(\"data\"))\n",
    ").withColumn(\n",
    "    \"mes\",\n",
    "    F.month(F.col(\"data\"))\n",
    ").withColumn(\n",
    "    \"ano_mes\",\n",
    "    F.date_format(F.col(\"data\"), \"yyyy-MM\")\n",
    ")\n",
    "\n",
    "print(\"2️. Identificando dia da semana...\")\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"dia_semana\",\n",
    "    F.dayofweek(F.col(\"data\"))\n",
    ").withColumn(\n",
    "    \"nome_dia_semana\",\n",
    "    F.when(F.col(\"dia_semana\") == 1, \"Domingo\")\n",
    "    .when(F.col(\"dia_semana\") == 2, \"Segunda\")\n",
    "    .when(F.col(\"dia_semana\") == 3, \"Terça\")\n",
    "    .when(F.col(\"dia_semana\") == 4, \"Quarta\")\n",
    "    .when(F.col(\"dia_semana\") == 5, \"Quinta\")\n",
    "    .when(F.col(\"dia_semana\") == 6, \"Sexta\")\n",
    "    .when(F.col(\"dia_semana\") == 7, \"Sábado\")\n",
    ")\n",
    "\n",
    "print(\"3️. Criando valor_com_sinal para fluxo de caixa...\")\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"valor_com_sinal\",\n",
    "    F.when(F.col(\"tipo\") == \"entrada\", F.col(\"valor\"))\n",
    "    .otherwise(-F.col(\"valor\"))\n",
    ")\n",
    "\n",
    "print(\"4️. Identificando transações de alto valor...\")\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"alto_valor\",\n",
    "    F.when(F.col(\"valor\") > 50000, True).otherwise(False)\n",
    ")\n",
    "\n",
    "print(\"5️. Calculando trimestre...\")\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"trimestre\",\n",
    "    F.quarter(F.col(\"data\"))\n",
    ")\n",
    "\n",
    "print(\"\\n Enriquecimento concluído!\")\n",
    "print(f\" Total de colunas agora: {len(df_enriched.columns)}\")\n",
    "\n",
    "print(\"\\n Amostra com campos calculados:\")\n",
    "display(df_enriched.select(\n",
    "    \"data\", \"valor\", \"tipo\", \"ano_mes\", \n",
    "    \"nome_dia_semana\", \"valor_com_sinal\", \"alto_valor\"\n",
    ").limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c5e0bd-a63d-4bb1-8c6a-9fd5e1be0449",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. SALVAR CAMADA SILVER\n",
    "# ============================================\n",
    "\n",
    "print(\"Salvando dados na camada Silver...\")\n",
    "\n",
    "# timestamp de processamento Silver\n",
    "df_silver = df_enriched.withColumn(\n",
    "    \"silver_processed_at\",\n",
    "    F.current_timestamp()\n",
    ")\n",
    "\n",
    "df_silver = df_silver.select(\n",
    "    \"bronze_id\",\n",
    "    \"load_timestamp\",\n",
    "    \"silver_processed_at\",\n",
    "    \"source_file\",\n",
    "    \"data\",\n",
    "    \"ano\",\n",
    "    \"mes\",\n",
    "    \"ano_mes\",\n",
    "    \"trimestre\",\n",
    "    \"dia_semana\",\n",
    "    \"nome_dia_semana\",\n",
    "    \"descricao\",\n",
    "    \"valor\",\n",
    "    \"valor_com_sinal\",\n",
    "    \"tipo\",\n",
    "    \"categoria\",\n",
    "    \"alto_valor\"\n",
    ")\n",
    "\n",
    "df_silver.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(TARGET_TABLE)\n",
    "\n",
    "print(\" Tabela Silver criada\")\n",
    "\n",
    "silver_count = spark.read.table(TARGET_TABLE).count()\n",
    "print(f\" Linhas na tabela Silver: {silver_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105206d8-090f-42f9-a455-a538f1c2db55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#============================================\n",
    "# PASSO 6: VALIDAÇÃO FINAL SILVER\n",
    "# ============================================\n",
    "\n",
    "print(\"Validação camada Silver\\n\")\n",
    "\n",
    "df_val = spark.read.table(TARGET_TABLE)\n",
    "\n",
    "print(\"1️. Verificando integridade:\")\n",
    "nulls_data = df_val.filter(F.col(\"data\").isNull()).count()\n",
    "nulls_valor = df_val.filter(F.col(\"valor\").isNull()).count()\n",
    "print(f\"   NULLs em 'data': {nulls_data} (deve ser 0)\")\n",
    "print(f\"   NULLs em 'valor': {nulls_valor} (deve ser 0)\")\n",
    "\n",
    "print(\"\\n 2️. Verificando valores:\")\n",
    "valores_invalidos = df_val.filter(F.col(\"valor\") <= 0).count()\n",
    "print(f\"   Valores <=0: {valores_invalidos} (deve ser 0)\")\n",
    "\n",
    "print(\"\\n 3️. Verificando duplicatas:\")\n",
    "total = df_val.count()\n",
    "distinct = df_val.select(\"data\", \"descricao\", \"valor\").distinct().count()\n",
    "duplicatas = total - distinct\n",
    "print(f\"   Duplicatas: {duplicatas} (deve ser 0)\")\n",
    "\n",
    "print(\"\\n 4️. Distribuição por categoria:\")\n",
    "df_val.groupBy(\"categoria\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"quantidade\"),\n",
    "        F.sum(\"valor\").alias(\"valor_total\")\n",
    "    ) \\\n",
    "    .orderBy(\"quantidade\", ascending=False) \\\n",
    "    .show()\n",
    "\n",
    "print(\"5️. Período dos dados:\")\n",
    "df_val.select(\n",
    "    F.min(\"data\").alias(\"data_inicial\"),\n",
    "    F.max(\"data\").alias(\"data_final\"),\n",
    "    F.countDistinct(\"ano_mes\").alias(\"meses_distintos\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n Camada Silver validada e pronta para analise.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_clean_silver_transacoes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
